{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8DM40: Assignment Week 1 (Group 5):\n",
    "# Two simple machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# add subfolder that contains all the function implementations\n",
    "# to the system path so we can import them\n",
    "sys.path.append('code/')\n",
    "\n",
    "# Get the diabetes data\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Get the breast cancer data\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question*** (in text): Why we need to use the `np.newaxis` expression in the examples above? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:*** If you do not use np.newaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "X = diabetes.data[:,3]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get a vector with shape (442,) instead of an array with shape (442,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises + Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement training and evaluation of a linear regression model on the diabetes dataset using only matrix multiplication, inversion and transpose operations. Report the mean squared error of the model.\n",
    "\n",
    "To get you started we have implemented the first part of this exercise (fitting of the model) as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters:\n",
      " [[ 152.34786452]\n",
      " [ -16.57607993]\n",
      " [-254.66532396]\n",
      " [ 560.98630022]\n",
      " [ 278.91811152]\n",
      " [-393.41357305]\n",
      " [  97.05460405]\n",
      " [ -19.0023093 ]\n",
      " [ 169.46450327]\n",
      " [ 632.95050374]\n",
      " [ 114.21638941]]\n",
      "\n",
      "Mean squared error:  2794.5690145007284\n"
     ]
    }
   ],
   "source": [
    "# The actual implementation is in linear_regression.py,\n",
    "from linear_regression import *\n",
    "\n",
    "# Load the dataset, split in training and testing set\n",
    "X_train = diabetes.data[:300, :]\n",
    "y_train = diabetes.target[:300, np.newaxis]\n",
    "X_test = diabetes.data[300:, :]\n",
    "y_test = diabetes.target[300:, np.newaxis]\n",
    "\n",
    "# Determine the parameters from the training data with the least squared method\n",
    "w_hat = lsq(X_train, y_train)\n",
    "\n",
    "# Print the parameters\n",
    "print('Fitted parameters:\\n', w_hat)\n",
    "\n",
    "# Determine mean squared error (mse)\n",
    "mean_sq_error = mse(X_test, y_test, w_hat)\n",
    "print('\\nMean squared error: ', mean_sq_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted linear regression\n",
    "\n",
    "Assume that in the dataset that you use to train a linear regression model, there are identical versions of some samples. This problem can be reformulated to a weighted linear regression problem where the matrices $\\boldsymbol{\\mathrm{X}}$ and $\\boldsymbol{\\mathrm{Y}}$ (or the vector $\\boldsymbol{\\mathrm{y}}$ if there is only a single target/output variable) contain only the unique data samples, and a vector $\\boldsymbol{\\mathrm{d}}$ is introduced that gives more weight to samples that appear multiple times in the original dataset (for example, the sample that appears 3 times has a corresponding weight of 3). \n",
    "\n",
    "<p><font color='#770a0a'>Derive the expression for the least-squares solution of a weighted linear regression model (note that in addition to the matrices $\\boldsymbol{\\mathrm{X}}$ and $\\boldsymbol{\\mathrm{Y}}$, the solution should include a vector of weights $\\boldsymbol{\\mathrm{d}}$).</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "Notation:\\\n",
    "Vector: $\\vec{a}$\\\n",
    "Tensor: $\\boldsymbol{\\mathrm{A}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weighted linear regression, the sum of squares is:\n",
    "\\begin{equation}\n",
    "{RSS}_{w}(\\vec{w}) = \\sum_{i=1}^{N}{d_i(y_i- \\vec{x_i}^T \\vec{w} )}\n",
    "\\end{equation}\n",
    "Each squared error gets multiplied by a corresponding weight instead of having multiple instances in the input-output data where the same error would be added to the sum multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert to tensor notation, we need to be able to multiple element-wise, say $\\vec{a} * \\vec{b} = \\vec{c}$, where $\\vec{c}$ is the same shape as the other 2 vectors, and $c_i = a_i b_i$ for element $i$. All the vectors have the same length. Note that $\\vec{a} * \\vec{b} = \\vec{b} * \\vec{a}$.\n",
    "\n",
    "For tensors, say $\\boldsymbol{\\mathrm{A}} * \\vec{b} = \\boldsymbol{\\mathrm{C}}$, the dimensions need to be $\\boldsymbol{\\mathrm{A}} \\in R^{m \\times n}; \\vec{b} \\in R^{m \\times 1}; \\boldsymbol{\\mathrm{C}} \\in R^{m \\times n}$, i.e. the resulting tensor has the same dimensions as the original, and the length of the vector $\\vec{b}$ needs to be the same as the number of rows of $\\boldsymbol{\\mathrm{A}}$ (or in the case of $\\boldsymbol{\\mathrm{A}} * \\vec{b}^T$, the same number of columns). Note that here also, $\\boldsymbol{\\mathrm{A}} * \\vec{b} = \\vec{b} * \\boldsymbol{\\mathrm{A}}$. \n",
    "\n",
    "Using this notation, the sum of squares becomes:\n",
    "\\begin{equation}\n",
    "{RSS}_{w}(\\vec{w}) = (\\vec{y}-\\vec{X} \\vec{w})^T (\\vec{y}-\\vec{X} \\vec{w}) * \\vec{d}\n",
    "\\end{equation}\n",
    "\n",
    "With $\\vec{d},\\vec{y} \\in R^{N \\times 1}; \\vec{w} \\in R^{p \\times 1}$ and $\\vec{X} \\in R^{N \\times p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiate ${RSS}_{w} (\\vec{w})$ to $\\vec{w}$:\n",
    "\n",
    "${RSS}_{w}(\\vec{w}) = (\\vec{y}-\\boldsymbol{\\mathrm{X}} \\vec{w})^T (\\vec{y} * \\vec{d} - \\boldsymbol{\\mathrm{X}} \\vec{w} * \\vec{d})$\n",
    "\n",
    "$\\frac{\\partial {RSS}_{w}}{\\partial \\vec{w}} = -\\boldsymbol{\\mathrm{X}}^T (\\vec{y} * \\vec{d} - \\boldsymbol{\\mathrm{X}} \\vec{w} * \\vec{d}) + (\\vec{y} -\\boldsymbol{\\mathrm{X}} \\vec{w})^T (- \\boldsymbol{\\mathrm{X}} * \\vec{d})$\n",
    "\n",
    "$\\frac{\\partial {RSS}_{w}}{\\partial \\vec{w}} = -\\boldsymbol{\\mathrm{X}}^T (\\vec{y} - \\boldsymbol{\\mathrm{X}} \\vec{w}) * \\vec{d} - (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T (\\vec{y} -\\boldsymbol{\\mathrm{X}} \\vec{w}) $\n",
    "\n",
    "On the first term, we need to apply $\\boldsymbol{\\mathrm{A}}^T \\cdot \\vec{b} * \\vec{c} = (\\boldsymbol{\\mathrm{A}} * \\vec{c})^T \\cdot \\vec{b}$, with $\\boldsymbol{\\mathrm{A}} \\in R^{m \\times n}; \\vec{b} \\in R^{m \\times 1}; \\vec{c} \\in R^{m \\times 1}$. This follows from dimension analysis (${n \\times m} \\cdot {m \\times 1} * {m \\times 1} = {n \\times 1} = ({n \\times m} * {1 \\times m}) \\cdot { m\\times 1}$).\n",
    "\n",
    "Apply to $\\frac{\\partial {RSS}_{w}}{\\partial \\vec{w}}$:\n",
    "\n",
    "$\\frac{\\partial {RSS}_{w}}{\\partial \\vec{w}} = -(\\boldsymbol{\\mathrm{X}} * \\vec{d})^T (\\vec{y} - \\boldsymbol{\\mathrm{X}} \\vec{w}) - (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T (\\vec{y} - \\boldsymbol{\\mathrm{X}} \\vec{w}) $\n",
    "\n",
    "Result of differentiation of ${RSS}_{w}$ to $\\vec{w}$:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial {RSS}_{w}}{\\partial \\vec{w}} = -2(\\boldsymbol{\\mathrm{X}} * \\vec{d})^T (\\vec{y} - \\boldsymbol{\\mathrm{X}} \\vec{w}) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for $\\vec{w}$:\n",
    "\n",
    "$(\\boldsymbol{\\mathrm{X}} * \\vec{d})^T (\\vec{y} - \\boldsymbol{\\mathrm{X}} \\vec{w}) = \\vec{0}$\n",
    "\n",
    "$ (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\vec{y} - (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\boldsymbol{\\mathrm{X}} \\vec{w} = \\vec{0}$\n",
    "\n",
    "$(\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\boldsymbol{\\mathrm{X}} \\vec{w} = (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\vec{y}$\n",
    "\n",
    "With as result for weighted linear regression:\n",
    "\\begin{equation}\n",
    "\\vec{w} = ((\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\boldsymbol{\\mathrm{X}})^{-1} (\\boldsymbol{\\mathrm{X}} * \\vec{d})^T \\vec{y}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check result with dimension analysis:\n",
    "\n",
    "${p \\times 1} = (({N \\times p} * {N \\times 1})^T \\cdot {N \\times p})^{-1} \\cdot ({N \\times p} * {N \\times 1})^T \\cdot {N \\times 1}$\n",
    "\n",
    "${p \\times 1} = ({p \\times N} \\cdot {N \\times p})^{-1} \\cdot {p \\times N} \\cdot {N \\times 1}$\n",
    "\n",
    "${p \\times 1} = ({p \\times p})^{-1} \\cdot {p \\times 1}$\n",
    "\n",
    "Note that the matrix to be inverted is square, as it needs to be.\n",
    "\n",
    "Check result if unweighted/normal: For the unweighted case, $\\vec{d}$ is a vector of ones. Then $\\boldsymbol{\\mathrm{X}} * \\vec{d} = \\boldsymbol{\\mathrm{X}}$. Indeed, substituting this gives the unweighted solution: $\\vec{w} = (\\boldsymbol{\\mathrm{X}}^T \\boldsymbol{\\mathrm{X}})^{-1} \\boldsymbol{\\mathrm{X}}^T \\vec{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN classification\n",
    "\n",
    "Implement a $k$-Nearest neighbors classifier from scratch in Python using only basic matrix operations with `numpy` and `scipy`. Train and evaluate the classifier on the breast cancer dataset, using all features. Show the performance of the classifier for different values of $k$ (plot the results in a graph). Note that for optimal results, you should normalize the features (e.g. to the $[0, 1]$ range or to have a zero mean and unit standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'normalisation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d0fdab7ff749>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnormalisation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mk_nn_classification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualisation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'normalisation'"
     ]
    }
   ],
   "source": [
    "from normalisation import *\n",
    "from k_nn_classification import *\n",
    "from visualisation import *\n",
    "\n",
    "#load data\n",
    "X = breast_cancer.data\n",
    "#normalize data\n",
    "X = normalize(X)\n",
    "\n",
    "#divide dataset in train and test sets\n",
    "X_train = X[:350]\n",
    "y_train = breast_cancer.target[:350, np.newaxis]\n",
    "X_test = X[350:]\n",
    "y_test = breast_cancer.target[350:, np.newaxis]\n",
    "\n",
    "k = list(range(1,11)) #assign different values for k \n",
    "correct = [] \n",
    "\n",
    "#perform model on all values for k, calculate the overlap with the prediction and the  test target vector\n",
    "for i in k: \n",
    "    acc = accuracy(X_train, X_test, y_train, y_test, i)\n",
    "    correct.append(acc)\n",
    "\n",
    "#visualize the accuracy for each value of k \n",
    "visualisation(correct,k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN regression\n",
    "\n",
    "Modify the $k$-NN implementation to do regression instead of classification. Compare the performance of the linear regression model and the $k$-NN regression model on the diabetes dataset for different values of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "[???]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-conditional probability\n",
    "\n",
    "Compute and visualize the class-conditional probability (conditional probability where the class label is the conditional variable, i.e. $P(X = x \\mid Y = y)$ for all features in the breast cancer dataset. Assume a Gaussian distribution.\n",
    "\n",
    "<p><font color='#770a0a'>Based on visual analysis of the plots, which individual feature can best discriminate between the two classes? Motivate your answer.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sep_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0ca18772c1c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msep_class\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Step 1: Load the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbreast_cancer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sep_class'"
     ]
    }
   ],
   "source": [
    "from sep_class import * \n",
    "from statistics import * \n",
    "\n",
    "#Step 1: Load the data.\n",
    "breast_cancer = load_breast_cancer()\n",
    "#Step 2: split the dataset into a training and testing set and operate on each feature seperately per loop.  \n",
    "for i in range(len(breast_cancer.data[0])):  \n",
    "    X_train = breast_cancer.data[:300, np.newaxis, i]\n",
    "    y_train = breast_cancer.target[:300]\n",
    "    X_test =  breast_cancer.data[300:, np.newaxis, i]\n",
    "    y_test =  breast_cancer.target[300:, np.newaxis]\n",
    "\n",
    "    #Step 3: Seperate the targets (0 or 1) for the feature.\n",
    "    seperated_classes = sep_class(X_train, y_train) #This will return 2 lists within a list with each list correseponding to either class 0 or 1\n",
    "    list_class_0 = seperated_classes[0]\n",
    "    list_class_1 = seperated_classes[1]\n",
    "    \n",
    "    #Step 4: Determine the mean and standard deviation of the feature per class.\n",
    "    mean_class_0 = mean(list_class_0)\n",
    "    std_class_0 = std(list_class_0)\n",
    "\n",
    "    mean_class_1 = mean(list_class_1)\n",
    "    std_class_1 = std(list_class_1)\n",
    "\n",
    "    #Step 5: plot the histograms per class per feature with corresponding normal distribution\n",
    "    x_class_0 = np.linspace(min(list_class_0), max(list_class_0), 100)\n",
    "    plt.hist(list_class_0, bins=\"auto\",normed=True, alpha = 0.8, color= 'red', label='Class 0')\n",
    "    plt.plot(x_class_0, mlab.normpdf(x_class_0, mean_class_0, std_class_0), color='black')\n",
    "    \n",
    "    x_class_1 = np.linspace(min(list_class_1), max(list_class_1), 100)\n",
    "    plt.hist(list_class_1, bins=\"auto\",normed=True,alpha = 0.8, color='green', label='Class 1')\n",
    "    plt.plot(x_class_1, mlab.normpdf(x_class_1, mean_class_1, std_class_1), color = 'black')\n",
    "    \n",
    "    pyplot.legend(loc='upper right')\n",
    "    pyplot.title('Feature ' + str(i+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
